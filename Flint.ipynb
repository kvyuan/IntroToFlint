{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flint Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from ts.flint import FlintContext, summarizers, windows\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "sc=pyspark.SparkContext().getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "flintContext = FlintContext(sqlContext)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a flint dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+\n",
      "|               time|  v|\n",
      "+-------------------+---+\n",
      "|2018-08-19 00:00:00|1.0|\n",
      "|2018-08-21 00:00:00|2.0|\n",
      "|2018-08-24 00:00:00|3.0|\n",
      "+-------------------+---+\n",
      "\n",
      "<class 'ts.flint.dataframe.TimeSeriesDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "l = [('2018-08-19', 1.0), ('2018-08-21', 2.0), ('2018-08-24', 3.0)]\n",
    "rdd = sc.parallelize(l)\n",
    "dat = rdd.map(lambda x: Row(time=x[0], v=x[1]))\n",
    "df = spark.createDataFrame(data=dat)\n",
    "df = df.withColumn('time', from_utc_timestamp(col('time'), 'UTC'))\n",
    "flint_df = flintContext.read.dataframe(df)\n",
    "flint_df.show()\n",
    "print(type(flint_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute sum of column v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               time|v_sum|\n",
      "+-------------------+-----+\n",
      "|1970-01-01 00:00:00|  6.0|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_sum = flint_df.summarize(summarizers.sum(\"v\"))\n",
    "value_sum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Compute 3-day moving average using Flint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------+\n",
      "|               time|  v|v_mean|\n",
      "+-------------------+---+------+\n",
      "|2018-08-19 00:00:00|1.0|   1.0|\n",
      "|2018-08-21 00:00:00|2.0|   1.5|\n",
      "|2018-08-24 00:00:00|3.0|   3.0|\n",
      "+-------------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inclusive\n",
    "w = windows.past_absolute_time('2day')\n",
    "threedayMA = flint_df.summarizeWindows(w, summarizers.mean('v'))\n",
    "threedayMA.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute 3-day moving average using sql function and window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---------------+\n",
      "|               time|  v|rolling_average|\n",
      "+-------------------+---+---------------+\n",
      "|2018-08-19 00:00:00|1.0|            1.0|\n",
      "|2018-08-21 00:00:00|2.0|            1.5|\n",
      "|2018-08-24 00:00:00|3.0|            3.0|\n",
      "+-------------------+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "#function to calculate number of seconds from number of days\n",
    "days = lambda i: i * 86400\n",
    "\n",
    "\n",
    "#create window by casting timestamp to long (number of seconds)\n",
    "w = (Window.orderBy(F.col(\"time\").cast('long')).rangeBetween(-days(2), 0))\n",
    "\n",
    "df = df.withColumn('rolling_average', F.avg(\"v\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compute 2-minute moving average using sql function and window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------+\n",
      "|               time|  v|v_mean|\n",
      "+-------------------+---+------+\n",
      "|2018-08-19 00:00:00|1.0|   1.0|\n",
      "|2018-08-20 23:59:00|1.0|   1.0|\n",
      "|2018-08-21 00:00:00|2.0|   1.5|\n",
      "|2018-08-24 00:00:00|3.0|   3.0|\n",
      "+-------------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = [('2018-08-19', 1.0), ('2018-08-20 23:59:00', 1.0), ('2018-08-21', 2.0), ('2018-08-24', 3.0)]\n",
    "rdd = sc.parallelize(l)\n",
    "dat = rdd.map(lambda x: Row(time=x[0], v=x[1]))\n",
    "df = spark.createDataFrame(data=dat)\n",
    "df = df.withColumn('time', from_utc_timestamp(col('time'), 'UTC'))\n",
    "flint_df = flintContext.read.dataframe(df)\n",
    "w = windows.past_absolute_time('1min')\n",
    "onedayMA = flint_df.summarizeWindows(w, summarizers.mean('v'))\n",
    "onedayMA.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Left join two dataframes with misaligned timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|left_v|               time|\n",
      "+------+-------------------+\n",
      "|   5.0|2019-11-13 00:00:00|\n",
      "|   8.0|2019-11-14 00:00:00|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = [('2019-11-13', 5.0), ('2019-11-14', 8.0)]\n",
    "rdd = sc.parallelize(l)\n",
    "dat = rdd.map(lambda x: Row(time=x[0], left_v=x[1]))\n",
    "df = spark.createDataFrame(data=dat)\n",
    "df = df.withColumn('time', from_utc_timestamp(col('time'), 'UTC'))\n",
    "left = flintContext.read.dataframe(df)\n",
    "l = [('2019-11-11', 1.0), ('2019-11-14', 4.0)]\n",
    "rdd = sc.parallelize(l)\n",
    "dat = rdd.map(lambda x: Row(time=x[0], right_v=x[1]))\n",
    "df = spark.createDataFrame(data=dat)\n",
    "df = df.withColumn('time', from_utc_timestamp(col('time'), 'UTC'))\n",
    "right = flintContext.read.dataframe(df)\n",
    "\n",
    "left.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|right_v|               time|\n",
      "+-------+-------------------+\n",
      "|    1.0|2019-11-11 00:00:00|\n",
      "|    4.0|2019-11-14 00:00:00|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------+\n",
      "|               time|left_v|right_v|\n",
      "+-------------------+------+-------+\n",
      "|2019-11-13 00:00:00|   5.0|    1.0|\n",
      "|2019-11-14 00:00:00|   8.0|    4.0|\n",
      "+-------------------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = left.leftJoin(right, tolerance='3day')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
